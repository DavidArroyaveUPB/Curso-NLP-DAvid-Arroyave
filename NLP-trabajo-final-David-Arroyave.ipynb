{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSZruQHnBkEO"
   },
   "source": [
    "# Trabajo Final procesamiento de lenguaje natural (NLP) <a class=\"tocSkip\">\n",
    "## Universidad Pontificia Bolivariana <a class=\"tocSkip\">\n",
    "\n",
    "**Estudiante:** xxxxxxxxxx\n",
    "\n",
    "**ID:** xxxxxxxxxx\n",
    "\n",
    "\n",
    "\n",
    "**Subir Este notebook de Trabajo Final en su repositorio de GitHub. y enviar el link en **Microsoft TEAMS**\n",
    "\n",
    "Docente: [Jose R. Zapata](https://joserzapata.github.io)\n",
    "- https://joserzapata.github.io\n",
    "- https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo del Trabajo\n",
    "Realizar un proceso de Procesamiento de lenguaje natural (NLP) para dejar los datos preparados para ser usados con algoritmos de Machine Learning para Clasificaci칩n como objetivo final del trabajo.\n",
    "\n",
    "los datos preparados para ser usados con algoritmos de Machine Learning para Regresi칩n o Clasificaci칩n como objetivo final del trabajo.\n",
    "\n",
    "El trabajo se realizara en este jupyter notebook y subirlo a su repositorio de github creado en clase. (**Recuerde poner su nombre e informaci칩n**)\n",
    "\n",
    "## Las actividades a realizar\n",
    "    \n",
    "\n",
    "1) Limpiar los datos de texto.\n",
    "\n",
    "   - https://joserzapata.github.io/courses/nlp/procesamiento-basico/\n",
    "\n",
    "   - https://joserzapata.github.io/courses/nlp/preprocesamiento-texto/\n",
    "\n",
    "2) Realizar la representaci칩n de texto:\n",
    "\n",
    "   - https://joserzapata.github.io/courses/nlp/representaciones/\n",
    "\n",
    "   - Tokenizaci칩n\n",
    "   - Lematizaci칩n o stemming\n",
    "   - Representaci칩n de los datos de texto (Bag of Words o TF-IDF)\n",
    "\n",
    "3) Utilice un modelo de Machine Learning para clasificaci칩n para entrenar y evaluar el modelo.\n",
    "        \n",
    "    - Calcule estas las m칠tricas de evaluaci칩n (accuracy, precision, recall, f1-score) - https://joserzapata.github.io/courses/python-ciencia-datos/clasificacion/#evaluacion-modelo-simple\n",
    "\n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "*NOTA: No dude en contactarme para cualquier pregunta o inquietud :) por el chat de Teams o al correo\n",
    "joser.zapata@upb.edu.co*\n",
    "\n",
    "## EVALUACI칍N\n",
    "\n",
    "\n",
    "|Porcentaje en la evaluaci칩n | Descripci칩n| Nada | Incompleto | Completo \n",
    "| :---: |:---: |:---: |:---: |:---: \n",
    "| 5 % |**limpieza de los datos** |\n",
    "| 5 % | **Representacion de los datos** |\n",
    "| 5 % | **Machine Learning** <br> Entrenar y evaluar el modelo propuesto |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1784,
     "status": "ok",
     "timestamp": 1742313766605,
     "user": {
      "displayName": "Carlos Bustillo",
      "userId": "14895763228834044971"
     },
     "user_tz": 180
    },
    "id": "FbX4vPbang_e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLpaicLXninI"
   },
   "source": [
    "Carga del dataset\n",
    "\n",
    "El archivo  se carga en aproximadamente 10 segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1742313775953,
     "user": {
      "displayName": "Carlos Bustillo",
      "userId": "14895763228834044971"
     },
     "user_tz": 180
    },
    "id": "Xh8VOY5Mnjmo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50000 entries, 60826 to 17965\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   author_review_desc  50000 non-null  string\n",
      " 1   author_rating       50000 non-null  int64 \n",
      "dtypes: int64(1), string(1)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Usar su ID UPB Ejemplo: \"0028984798\"\n",
    "id_upb = \"000571109\"\n",
    "\n",
    "data_reviews = pd.read_parquet(\n",
    "    \"https://www.dropbox.com/scl/fi/gvk9yj8cn96oocr9z058x/filmaffinity_reviews_dataset.parquet?rlkey=xgvr00zvkxbkwqqavqutpsshg&st=xjb7xze9&dl=1\"\n",
    ")\n",
    "data_reviews = data_reviews.sample(n=50_000, random_state=int(id_upb))\n",
    "data_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGD-mkRRnm01"
   },
   "source": [
    "Ejemplo de algunas filas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1742313777216,
     "user": {
      "displayName": "Carlos Bustillo",
      "userId": "14895763228834044971"
     },
     "user_tz": 180
    },
    "id": "rIsJnVvPnnvc",
    "outputId": "a97d6896-3f9b-4a02-88fc-f3e6f84d0602"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_review_desc</th>\n",
       "      <th>author_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84194</th>\n",
       "      <td>Nos encontramos ante una bell칤sima pel칤cula a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36121</th>\n",
       "      <td>En cuanto a pel칤culas de hombres lobo estamos...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42819</th>\n",
       "      <td>Resumen de la pel칤cula: tomemos una historia ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123481</th>\n",
       "      <td>Porque dudo que a muchos de los que la califi...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97203</th>\n",
       "      <td>Es un pel칤cula simple con personajes arquet칤p...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       author_review_desc  author_rating\n",
       "84194   \n",
       "Nos encontramos ante una bell칤sima pel칤cula a...              8\n",
       "36121   \n",
       "En cuanto a pel칤culas de hombres lobo estamos...              8\n",
       "42819   \n",
       "Resumen de la pel칤cula: tomemos una historia ...              4\n",
       "123481  \n",
       "Porque dudo que a muchos de los que la califi...              9\n",
       "97203   \n",
       "Es un pel칤cula simple con personajes arquet칤p...              4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reviews.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKA9UPk6p7bZ"
   },
   "source": [
    "Evaluar los valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1742313779074,
     "user": {
      "displayName": "Carlos Bustillo",
      "userId": "14895763228834044971"
     },
     "user_tz": 180
    },
    "id": "2wwqoksvqQFk",
    "outputId": "fea4451b-9936-4eb7-b1b9-14fd83f7c72f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_review_desc    0\n",
       "author_rating         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso no hay nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisar si hay valores duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reviews.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay  valores duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiBcIGoZsQJC"
   },
   "source": [
    "## Clasificaci칩n Tradicional para An치lisis de Sentimientos y Categor칤as 游녨 游녩\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPUGUs9AmA_b"
   },
   "source": [
    "Definici칩n: Se considera rese침a positiva cuando la puntuaci칩n (\"author_rating\") es mayor que 6; negativa en caso contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZTzGi7tmMBN"
   },
   "source": [
    "Crear la variable binaria de sentimiento: 1 (positivo) si author_rating > 6, 0 (negativo) de lo contrario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1742314413450,
     "user": {
      "displayName": "Carlos Bustillo",
      "userId": "14895763228834044971"
     },
     "user_tz": 180
    },
    "id": "Wu66d05mmKtT"
   },
   "outputs": [],
   "source": [
    "UMBRAL = 6\n",
    "data_reviews[\"sentiment_bin\"] = (data_reviews[\"author_rating\"] > UMBRAL).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "\n",
    "X_data = data_reviews[\"author_review_desc\"]\n",
    "y_data = data_reviews[\"sentiment_bin\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir el dataset en entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data,\n",
    "    y_data,\n",
    "    test_size=0.2,\n",
    "    stratify=y_data,  # Mantener la proporci칩n de clases en ambos conjuntos\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An치lisis exploratorio de los datos\n",
    "\n",
    "para determinar que tipo de limpieza se debe realizar a los datos de texto de `X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Limpieza de los datos de texto\n",
    "\n",
    "Tomar los datos de `X_train` y aplicar las funciones de limpieza que considere necesarias\n",
    "\n",
    "Ayudas:\n",
    "\n",
    "- Convertir a min칰sculas\n",
    "- Eliminar caracteres especiales y n칰meros\n",
    "- Corregir palabras mal escritas\n",
    "- etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpiando 40000 rese침as de X_train...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4370689c03d84c2cac908f8ea94b6899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progreso de limpieza:   0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpiando 10000 rese침as de X_test...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58044d11aaed4ab38c7b1b3b016d0083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progreso de limpieza:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Limpieza completada ---\n",
      "\n",
      "EJEMPLO DE LIMPIEZA:\n",
      "------------------------\n",
      "RESE칌A ORIGINAL (X_train):\n",
      "\n",
      "El argumento es claro, hay algo m치s all치 de la muerte. Para ello el maestro nos introduce la historia de tres personajes, el primero, Damon, alguien con el don o la maldici칩n de poder poner en contacto a vivos y muertos, hecho que le atormenta. El segundo, una preciosa C칠lice de France, famosa reportera de televisi칩n, que tras llegar al abismo de la muerte, parece que empieza a reflexionar acerca de la experiencia que ha tenido. Finalmente, McLaren, un t칤mido ni침o inseparable de su gemelo que sufre una experiencia terrible que le marcar치 siempre.\n",
      "\n",
      "\n",
      "Hasta ah칤 todo vale, y la pel칤cula es entretenida, y en mi opini칩n nunca aburre. Bien es cierto que tiene momentos m치s brillantes que otros, sin embargo, y como indica Kirk Honeycutt (The Hollywood Reporter), el final decepciona. Pese a que el hilo narrativo es correcto falta algo en la trama que efectivamente nos haga vibrar de verdad.\n",
      "\n",
      "\n",
      "A칰n as칤, Clint no decepciona, y es una cinta que merece ser vista. Para m칤, lo mejor, el meollo del asunto, que hay tras la muerte (parece que este viejo baquero empieza a darse cuenta de sus ochenta y tantos y ciertas preguntas le vienen a la cabeza) as칤 como la m칰sica que me recuerda al final de \"Sin Perd칩n\". No habr치n salido con la sensaci칩n de tirar siete euros de entrada.\n",
      "\n",
      "------------------------\n",
      "RESE칌A LIMPIA (X_train_limpio):\n",
      "el argumento es claro hay algo m치s all치 de la muerte para ello el maestro nos introduce la historia de tres personajes el primero damon alguien con el don o la maldici칩n de poder poner en contacto a vivos y muertos hecho que le atormenta el segundo una preciosa c칠lice de france famosa reportera de televisi칩n que tras llegar al abismo de la muerte parece que empieza a reflexionar acerca de la experiencia que ha tenido finalmente mclaren un t칤mido ni침o inseparable de su gemelo que sufre una experiencia terrible que le marcar치 siempre hasta ah칤 todo vale y la pel칤cula es entretenida y en mi opini칩n nunca aburre bien es cierto que tiene momentos m치s brillantes que otros sin embargo y como indica kirk honeycutt the hollywood reporter el final decepciona pese a que el hilo narrativo es correcto falta algo en la trama que efectivamente nos haga vibrar de verdad a칰n as칤 clint no decepciona y es una cinta que merece ser vista para m칤 lo mejor el meollo del asunto que hay tras la muerte parece que este viejo baquero empieza a darse cuenta de sus ochenta y tantos y ciertas preguntas le vienen a la cabeza as칤 como la m칰sica que me recuerda al final de sin perd칩n no habr치n salido con la sensaci칩n de tirar siete euros de entrada\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configura tqdm para que funcione con los m칠todos .apply() de pandas\n",
    "# Esto nos dar치 una barra de progreso.\n",
    "tqdm.pandas(desc=\"Progreso de limpieza\")\n",
    "\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    \"\"\"\n",
    "    Funci칩n para limpiar el texto de las rese침as:\n",
    "    1. Convierte a min칰sculas.\n",
    "    2. Elimina puntuaci칩n, n칰meros y caracteres especiales.\n",
    "    Se preservan caracteres del espa침ol (치, 칠, 칤, 칩, 칰, 칲, 침).\n",
    "    3. Elimina espacios en blanco extra.\n",
    "    \"\"\"\n",
    "    # Asegurarnos de que el input es un string\n",
    "    if not isinstance(texto, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Convertir a min칰sculas\n",
    "    texto = texto.lower()\n",
    "\n",
    "    # 2. Eliminar caracteres especiales y n칰meros\n",
    "    # Usamos regex para mantener solo letras (incluyendo acentos y 침) y espacios\n",
    "    texto = re.sub(r\"[^a-z치칠칤칩칰칲침\\s]\", \"\", texto)\n",
    "\n",
    "    # 3. Eliminar espacios en blanco extra\n",
    "    # Reemplaza secuencias de uno o m치s espacios con un solo espacio\n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
    "\n",
    "    return texto\n",
    "\n",
    "\n",
    "# --- Aplicar la limpieza ---\n",
    "\n",
    "# (Asumiendo que X_train y X_test ya existen en memoria, como en el notebook)\n",
    "\n",
    "print(f\"Limpiando {len(X_train)} rese침as de X_train...\")\n",
    "# Usamos .progress_apply() gracias a tqdm para ver el avance\n",
    "X_train_limpio = X_train.progress_apply(limpiar_texto)\n",
    "\n",
    "print(f\"Limpiando {len(X_test)} rese침as de X_test...\")\n",
    "# Es fundamental aplicar EXACTAMENTE la misma limpieza a los datos de prueba\n",
    "X_test_limpio = X_test.progress_apply(limpiar_texto)\n",
    "\n",
    "print(\"\\n--- Limpieza completada ---\")\n",
    "\n",
    "# --- Verificar el resultado ---\n",
    "# Mostramos un ejemplo antes y despu칠s\n",
    "# (Usamos .iloc[0] para obtener la primera fila de la Serie de entrenamiento)\n",
    "print(\"\\nEJEMPLO DE LIMPIEZA:\")\n",
    "print(\"------------------------\")\n",
    "print(\"RESE칌A ORIGINAL (X_train):\")\n",
    "print(X_train.iloc[0])\n",
    "print(\"------------------------\")\n",
    "print(\"RESE칌A LIMPIA (X_train_limpio):\")\n",
    "print(X_train_limpio.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Representacion del texto\n",
    "\n",
    "Luego de tener los datos limpios, realizar la representaci칩n de los datos de texto para poder usarse en modelos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando recursos de NLTK (stopwords, punkt)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/vscode/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/vscode/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursos descargados.\n",
      "Se cargaron 313 stopwords en espa침ol.\n",
      "Ejemplos: ['de', 'contra', 'tuya', 'estuviera', 'hubieras', 'fuerais', 'tuvierais']\n",
      "\n",
      "Tokenizador con stemming configurado.\n",
      "Ejemplo de stemming:\n",
      "  'pel칤culas', 'pel칤cula', 'pelicul칩n' -> 'pelicul'\n",
      "\n",
      "Vectorizador TF-IDF configurado.\n",
      "Iniciando vectorizaci칩n...\n",
      "Ajustando (fit) el vectorizador y transformando X_train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/NLP_PabloZapataOchoa/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "/workspaces/NLP_PabloZapataOchoa/.venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['algun', 'com', 'contr', 'cuand', 'desd', 'dond', 'durant', 'eram', 'estab', 'estais', 'estam', 'estan', 'estand', 'estaran', 'estaras', 'esteis', 'estem', 'esten', 'estes', 'estuv', 'fuer', 'fues', 'fuim', 'fuist', 'hab', 'habr', 'habran', 'habras', 'hast', 'hem', 'hub', 'mas', 'mia', 'mias', 'mio', 'mios', 'much', 'nad', 'nosotr', 'nuestr', 'par', 'per', 'poc', 'porqu', 'qui', 'seais', 'seam', 'sent', 'ser', 'seran', 'seras', 'si', 'sient', 'sint', 'sobr', 'som', 'suy', 'tambien', 'tant', 'ten', 'tendr', 'tendran', 'tendras', 'teng', 'tien', 'tod', 'tuv', 'tuy', 'vosotr', 'vuestr'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformando X_test...\n",
      "\n",
      "--- Representaci칩n completada ---\n",
      "\n",
      "Forma (shape) de la matriz X_train_tfidf: (40000, 5000)\n",
      "Forma (shape) de la matriz X_test_tfidf: (10000, 5000)\n",
      "\n",
      "Explicaci칩n de la forma:\n",
      " - 40000 filas: (n칰mero de rese침as en X_train)\n",
      " - 5000 columnas: (el vocabulario de max_features)\n",
      "\n",
      "Algunas features (palabras/n-grams) aprendidas por el vectorizador:\n",
      "['abaj', 'blanchett', 'corean', 'ello', 'grup', 'lagun', 'nazis', 'per ser', 'reserv', 'tant pelicul']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# --- 1. Preparaci칩n de Stopwords y Stemmer ---\n",
    "\n",
    "# Descargar los recursos de NLTK (stopwords) si no est치n presentes\n",
    "try:\n",
    "    nltk.data.find(\"corpora/stopwords\")\n",
    "    nltk.data.find(\"tokenizers/punkt\")  # El stemmer lo puede necesitar\n",
    "except LookupError:\n",
    "    print(\"Descargando recursos de NLTK (stopwords, punkt)...\")\n",
    "    nltk.download(\"stopwords\")\n",
    "    nltk.download(\"punkt\")\n",
    "    print(\"Recursos descargados.\")\n",
    "\n",
    "# Cargar stopwords en espa침ol\n",
    "spanish_stopwords = list(stopwords.words(\"spanish\"))\n",
    "print(f\"Se cargaron {len(spanish_stopwords)} stopwords en espa침ol.\")\n",
    "print(f\"Ejemplos: {spanish_stopwords[::50]}\")  # Muestra algunas\n",
    "\n",
    "# Instanciar el Stemmer en espa침ol\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "# --- 2. Definici칩n del Tokenizador con Stemming ---\n",
    "\n",
    "# TfidfVectorizer no tiene un par치metro 'stemmer',\n",
    "# pero podemos pasarle una funci칩n 'tokenizer' personalizada.\n",
    "\n",
    "# Primero, obtenemos el tokenizador por defecto de scikit-learn\n",
    "# (Este sabe c칩mo manejar puntuaci칩n y espacios que el Paso 1 pudo dejar)\n",
    "default_tokenizer = TfidfVectorizer().build_tokenizer()\n",
    "\n",
    "\n",
    "def stemmed_tokenizer(doc):\n",
    "    \"\"\"\n",
    "    Funci칩n que primero tokeniza (separa en palabras) y luego\n",
    "    aplica stemming a cada token.\n",
    "    \"\"\"\n",
    "    # Usamos el tokenizador por defecto\n",
    "    tokens = default_tokenizer(doc)\n",
    "    # Aplicamos stemming a cada token\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens\n",
    "\n",
    "\n",
    "print(\"\\nTokenizador con stemming configurado.\")\n",
    "print(\"Ejemplo de stemming:\")\n",
    "print(f\"  'pel칤culas', 'pel칤cula', 'pelicul칩n' -> '{stemmer.stem('pel칤culas')}'\")\n",
    "\n",
    "\n",
    "# --- 3. Configuraci칩n del Vectorizador TF-IDF ---\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=stemmed_tokenizer,  # Usar nuestra funci칩n personalizada\n",
    "    stop_words=spanish_stopwords,  # Eliminar palabras comunes\n",
    "    ngram_range=(1, 2),  # Considerar palabras solas (1-gram) y pares (2-gram)\n",
    "    max_features=5000,  # Limitar vocabulario a las 5000 features m치s relevantes\n",
    "    min_df=3,  # Ignorar palabras/n-grams que aparezcan en < 3 rese침as\n",
    ")\n",
    "\n",
    "print(\"\\nVectorizador TF-IDF configurado.\")\n",
    "\n",
    "# --- 4. Aplicar la representaci칩n (Fit y Transform) ---\n",
    "\n",
    "# (Asumiendo que X_train_limpio y X_test_limpio existen del Paso 1)\n",
    "\n",
    "print(\"Iniciando vectorizaci칩n...\")\n",
    "\n",
    "# 1. Aprender el vocabulario (fit) y transformar los datos de ENTRENAMIENTO\n",
    "print(\"Ajustando (fit) el vectorizador y transformando X_train...\")\n",
    "# X_train_limpio y y_train (del script original)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_limpio)\n",
    "\n",
    "# 2. SOLO transformar los datos de PRUEBA (usando el vocabulario aprendido)\n",
    "print(\"Transformando X_test...\")\n",
    "# X_test_limpio (del script original)\n",
    "X_test_tfidf = vectorizer.transform(X_test_limpio)\n",
    "\n",
    "print(\"\\n--- Representaci칩n completada ---\")\n",
    "\n",
    "# --- 5. Verificar el resultado ---\n",
    "print(f\"\\nForma (shape) de la matriz X_train_tfidf: {X_train_tfidf.shape}\")\n",
    "print(f\"Forma (shape) de la matriz X_test_tfidf: {X_test_tfidf.shape}\")\n",
    "\n",
    "print(\"\\nExplicaci칩n de la forma:\")\n",
    "print(f\" - {X_train_tfidf.shape[0]} filas: (n칰mero de rese침as en X_train)\")\n",
    "print(f\" - {X_train_tfidf.shape[1]} columnas: (el vocabulario de max_features)\")\n",
    "\n",
    "# Opcional: Mostrar algunas features (palabras/n-grams) aprendidas\n",
    "try:\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    print(\"\\nAlgunas features (palabras/n-grams) aprendidas por el vectorizador:\")\n",
    "    # Imprime una de cada 500 features para dar una idea\n",
    "    print(list(feature_names[::500]))\n",
    "except Exception as e:\n",
    "    print(f\"No se pudieron mostrar features: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Yvvopa2mVox"
   },
   "source": [
    "## 3) Entrenar un modelo de machine learning de clasificaci칩n\n",
    "\n",
    "Utilizar un modelo de clasificaci칩n para entrenar y evaluar el modelo con los datos preparados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1742314553868,
     "user": {
      "displayName": "Carlos Bustillo",
      "userId": "14895763228834044971"
     },
     "user_tz": 180
    },
    "id": "Xm_vBOhymWjZ",
    "outputId": "1f7e8842-fdb5-4580-998a-797d8c69e20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Paso 3: Entrenamiento del Modelo ---\n",
      "Modelo seleccionado: LogisticRegression\n",
      "\n",
      "Entrenando el modelo con los datos de X_train_tfidf...\n",
      "춰Modelo entrenado exitosamente!\n",
      "\n",
      "--- Iniciando Evaluaci칩n del Modelo ---\n",
      "Generando predicciones en el conjunto de prueba (X_test_tfidf)...\n",
      "Predicciones generadas.\n",
      "\n",
      "--- M칠tricas de Evaluaci칩n ---\n",
      "Accuracy (Exactitud): 0.8020\n",
      "Precision: 0.8037\n",
      "Recall (Sensibilidad): 0.8345\n",
      "F1 Score: 0.8188\n",
      "ROC AUC Score: 0.8837\n",
      "\n",
      "--- Reporte de Clasificaci칩n Detallado ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Negativo (0)       0.80      0.76      0.78      4639\n",
      "Positivo (1)       0.80      0.83      0.82      5361\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.80      0.80      0.80     10000\n",
      "weighted avg       0.80      0.80      0.80     10000\n",
      "\n",
      "\n",
      "--- Guardando artefactos del modelo ---\n",
      "Modelo guardado en 'modelo_sentimientos.joblib'\n",
      "Vectorizador guardado en 'vectorizador_tfidf.joblib'\n",
      "\n",
      "--- Proceso completado ---\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# (Asumimos que las variables X_train_tfidf, y_train, X_test_tfidf, y_test\n",
    "#  existen en memoria desde los pasos anteriores)\n",
    "\n",
    "print(\"--- Iniciando Paso 3: Entrenamiento del Modelo ---\")\n",
    "\n",
    "# --- 1. Instanciar el Modelo ---\n",
    "# Elegimos LogisticRegression. Es un modelo lineal robusto y r치pido,\n",
    "# ideal para datos TF-IDF que son \"dispersos\" (muchos ceros).\n",
    "# - random_state=42: Asegura que obtengamos los mismos resultados cada vez.\n",
    "# - max_iter=1000: Aumentamos las iteraciones para asegurar que el modelo\n",
    "#   \"converja\" (encuentre la mejor soluci칩n) con nuestros 5000 features.\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "print(f\"Modelo seleccionado: {type(model).__name__}\")\n",
    "\n",
    "# --- 2. Entrenar el Modelo ---\n",
    "print(\"\\nEntrenando el modelo con los datos de X_train_tfidf...\")\n",
    "# Usamos .fit() para que el modelo aprenda la relaci칩n entre\n",
    "# la matriz TF-IDF (las palabras) y el sentimiento (0 o 1).\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"춰Modelo entrenado exitosamente!\")\n",
    "\n",
    "# --- 3. Evaluar el modelo con los datos de prueba ---\n",
    "\n",
    "print(\"\\n--- Iniciando Evaluaci칩n del Modelo ---\")\n",
    "print(\"Generando predicciones en el conjunto de prueba (X_test_tfidf)...\")\n",
    "\n",
    "# Usamos .predict() en los datos de prueba (X_test_tfidf)\n",
    "# El modelo NUNCA vio estos datos durante el entrenamiento.\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Opcional: Calcular probabilidades para ROC-AUC\n",
    "# (Mide qu칠 tan bien distingue el modelo entre clases)\n",
    "y_pred_proba = model.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "print(\"Predicciones generadas.\")\n",
    "\n",
    "# --- 4. Calcular y Reportar M칠tricas ---\n",
    "# Comparamos las predicciones (y_pred) con las etiquetas reales (y_test)\n",
    "\n",
    "print(\"\\n--- M칠tricas de Evaluaci칩n ---\")\n",
    "\n",
    "# Accuracy: 쯈u칠 porcentaje de rese침as clasific칩 correctamente?\n",
    "# (Correctas / Total)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy (Exactitud): {acc:.4f}\")\n",
    "\n",
    "# Precision: De todas las que el modelo dijo que eran \"Positivas\",\n",
    "# 쯖u치ntas realmente lo eran?\n",
    "# (Importante si queremos evitar \"Falsos Positivos\")\n",
    "prec = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "\n",
    "# Recall (Sensibilidad): De todas las rese침as que *eran* \"Positivas\",\n",
    "# 쯖u치ntas logr칩 encontrar el modelo?\n",
    "# (Importante si queremos encontrar todos los \"Positivos Reales\")\n",
    "rec = recall_score(y_test, y_pred)\n",
    "print(f\"Recall (Sensibilidad): {rec:.4f}\")\n",
    "\n",
    "# F1-Score: La media arm칩nica entre Precision y Recall.\n",
    "# Un buen balance general entre ambas.\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# ROC-AUC: Mide la habilidad del modelo para discriminar\n",
    "# entre la clase positiva y negativa. (1.0 es perfecto, 0.5 es azar)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# Reporte de Clasificaci칩n: Un resumen completo\n",
    "print(\"\\n--- Reporte de Clasificaci칩n Detallado ---\")\n",
    "# Muestra Precision, Recall y F1 para ambas clases (0 y 1)\n",
    "print(\n",
    "    classification_report(y_test, y_pred, target_names=[\"Negativo (0)\", \"Positivo (1)\"])\n",
    ")\n",
    "\n",
    "\n",
    "# --- 5. Guardar el Modelo Entrenado y el Vectorizador ---\n",
    "# Es crucial guardar tambi칠n el 'vectorizer' del Paso 2,\n",
    "# porque para predecir en nuevos datos, necesitamos aplicar\n",
    "# EXACTAMENTE la misma transformaci칩n TF-IDF.\n",
    "\n",
    "print(\"\\n--- Guardando artefactos del modelo ---\")\n",
    "\n",
    "# Guardamos el modelo entrenado\n",
    "joblib.dump(model, \"modelo_sentimientos.joblib\")\n",
    "print(\"Modelo guardado en 'modelo_sentimientos.joblib'\")\n",
    "\n",
    "# (Asumiendo que 'vectorizer' es el nombre de tu TfidfVectorizer del Paso 2)\n",
    "try:\n",
    "    joblib.dump(vectorizer, \"vectorizador_tfidf.joblib\")\n",
    "    print(\"Vectorizador guardado en 'vectorizador_tfidf.joblib'\")\n",
    "except NameError:\n",
    "    print(\"ADVERTENCIA: No se pudo guardar el 'vectorizer'.\")\n",
    "    print(\"Aseg칰rate de que la variable 'vectorizer' (del Paso 2) est칠 en memoria.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el vectorizador: {e}\")\n",
    "\n",
    "print(\"\\n--- Proceso completado ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M칠tricas de Evaluaci칩n Clave:\n",
    "\n",
    "Accuracy (Exactitud): 0.8020 (80.2%)\n",
    "\n",
    "El modelo clasific칩 correctamente 8 de cada 10 rese침as en el conjunto de prueba. Este es un rendimiento s칩lido y robusto.\n",
    "\n",
    "ROC AUC Score: 0.8837 (88.4%)\n",
    "\n",
    "Esta m칠trica, que mide la capacidad del modelo para discriminar entre una rese침a positiva y una negativa, es muy alta. Un valor de 0.88 (cercano a 1.0) indica que el modelo es muy confiable para distinguir las clases.\n",
    "\n",
    "Reporte de Clasificaci칩n (F1-Score):\n",
    "\n",
    "Positivo (1): El modelo obtuvo un F1-Score de 0.82.\n",
    "\n",
    "Negativo (0): El modelo obtuvo un F1-Score de 0.78.\n",
    "\n",
    "El rendimiento es balanceado (Macro Avg F1-Score: 0.80), lo que demuestra que el modelo no tiene un sesgo significativo hacia una clase y es competente identificando tanto rese침as positivas como negativas.\n",
    "\n",
    "Conclusi칩n Final:\n",
    "\n",
    "El pipeline de NLP cl치sico (Limpieza -> Stemming -> TF-IDF) combinado con un modelo lineal (Regresi칩n Log칤stica) ha demostrado ser muy efectivo, alcanzando m치s de un 80% de exactitud. Los artefactos del modelo (modelo_sentimientos.joblib) y el vectorizador (vectorizador_tfidf.joblib) se han guardado exitosamente y est치n listos para ser desplega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wt0Mxr1YmZO0"
   },
   "source": [
    "### Evaluar el modelo con los datos de prueba\n",
    "\n",
    "Usar el modelo para predecir en `X_test` y evaluar con `y_test`\n",
    "\n",
    "**Nota:** Recuerde que `X_test` debe pasar por los mismos procesos de limpieza y representaci칩n que `X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1742314576802,
     "user": {
      "displayName": "Carlos Bustillo",
      "userId": "14895763228834044971"
     },
     "user_tz": 180
    },
    "id": "cJ9KMVyLmaX0",
    "outputId": "df20535f-365b-439f-db5a-0ae5270d0bfb"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"Reporte de clasificaci칩n:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8EMg20rzGVw"
   },
   "source": [
    "**Guardar el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1742314634787,
     "user": {
      "displayName": "Carlos Bustillo",
      "userId": "14895763228834044971"
     },
     "user_tz": 180
    },
    "id": "mP9pEc3ezIey",
    "outputId": "4aaff043-6a9e-49f5-ec0a-657b9b879b82"
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librer칤as Usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watermark import watermark\n",
    "\n",
    "print(watermark(python=True, iversions=True, globals_=globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Referencias\n",
    "- [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "- [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- [Classification of text documents using sparse features](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html)\n",
    "- Ejemplo de Entrenamiento y selecci칩n de Modelo de machine learning entre varios modelos <https://joserzapata.github.io/post/ciencia-datos-proyecto-python/6-model_selection/>\n",
    "- https://joserzapata.github.io/courses/python-ciencia-datos/python/\n",
    "- https://joserzapata.github.io/courses/python-ciencia-datos/pandas/\n",
    "- https://joserzapata.github.io/courses/python-ciencia-datos/machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docente: [Jose R. Zapata](https://joserzapata.github.io)\n",
    "\n",
    "- [https://joserzapata.github.io/](https://joserzapata.github.io/)\n",
    "- [https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/](https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO2onnY6t+Q8frrcGj/XGl2",
   "collapsed_sections": [
    "TcXzT5msVNnF",
    "yWXYzke6qtI3"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "template-data-science-container",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
